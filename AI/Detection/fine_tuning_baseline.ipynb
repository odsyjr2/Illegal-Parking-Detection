{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b535e91e",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea366349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ultralytics in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (8.3.168)\n",
      "Requirement already satisfied: opencv-python in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: tqdm in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: huggingface_hub in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (0.33.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from ultralytics) (3.10.3)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from ultralytics) (0.20.1+cu121)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from ultralytics) (1.25.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/lib/python3/dist-packages (from ultralytics) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from ultralytics) (2.5.1+cu121)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: py-cpuinfo in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from ultralytics) (2.32.4)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from ultralytics) (2.3.1)\n",
      "Requirement already satisfied: psutil in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from ultralytics) (7.0.0)\n",
      "Collecting numpy>=1.23.0\n",
      "  Using cached numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from huggingface_hub) (1.1.5)\n",
      "Requirement already satisfied: filelock in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from huggingface_hub) (4.14.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from huggingface_hub) (2025.7.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
      "Requirement already satisfied: triton==3.1.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: networkx in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.6.85)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.2\n",
      "    Uninstalling numpy-1.25.2:\n",
      "      Successfully uninstalled numpy-1.25.2\n",
      "Successfully installed numpy-2.2.6\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics opencv-python tqdm huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb3c542e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: torchaudio in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: fsspec in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: filelock in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: networkx in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: numpy in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 # cuda 12.1 ê¸°ì¤€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12acc902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numpy==1.25.2\n",
      "  Using cached numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.25.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.25.2\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy==1.25.2 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a155d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745e221b",
   "metadata": {},
   "source": [
    "# 2. Json -> YOLO txt ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22d7baef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_yolo(json_file_path, output_dir):\n",
    "    \"\"\"\n",
    "    JSON íŒŒì¼ì„ ì½ì–´ YOLO í¬ë§·ì˜ txt íŒŒì¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # ì´ë¯¸ì§€ í¬ê¸° ì •ë³´ ì¶”ì¶œ\n",
    "        resolution = data.get(\"meta\", {}).get(\"Resolution\", \"0x0\").split('x')\n",
    "        if len(resolution) != 2:\n",
    "            # print(f\"Skipping {json_file_path}: Invalid resolution format.\")\n",
    "            return\n",
    "            \n",
    "        img_width, img_height = int(resolution[0]), int(resolution[1])\n",
    "        if img_width == 0 or img_height == 0:\n",
    "            # print(f\"Skipping {json_file_path}: Image width or height is zero.\")\n",
    "            return\n",
    "\n",
    "        # ì–´ë…¸í…Œì´ì…˜ ì •ë³´ ì¶”ì¶œ\n",
    "        annotations = data.get(\"annotations\", {}).get(\"Bbox Annotation\", {})\n",
    "        boxes = annotations.get(\"Box\", [])\n",
    "        \n",
    "        if not boxes:\n",
    "            # Bounding Boxê°€ ì—†ëŠ” ê²½ìš°, ë¹ˆ txt íŒŒì¼ ìƒì„±\n",
    "            base_filename = os.path.basename(json_file_path)\n",
    "            txt_filename = os.path.splitext(base_filename)[0] + \".txt\"\n",
    "            open(os.path.join(output_dir, txt_filename), 'w').close()\n",
    "            return\n",
    "\n",
    "        yolo_data = []\n",
    "        for box in boxes:\n",
    "            # YOLO í¬ë§·ìœ¼ë¡œ ë³€í™˜\n",
    "            # í˜„ì¬ëŠ” ë‹¨ì¼ í´ë˜ìŠ¤(0)ë¡œ ì²˜ë¦¬\n",
    "            class_id = 0  \n",
    "            x, y, w, h = box['x'], box['y'], box['w'], box['h']\n",
    "            \n",
    "            x_center = (x + w / 2) / img_width\n",
    "            y_center = (y + h / 2) / img_height\n",
    "            width_norm = w / img_width\n",
    "            height_norm = h / img_height\n",
    "            \n",
    "            yolo_data.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {width_norm:.6f} {height_norm:.6f}\")\n",
    "\n",
    "        # YOLO í¬ë§·ìœ¼ë¡œ íŒŒì¼ ì €ì¥\n",
    "        base_filename = os.path.basename(json_file_path)\n",
    "        txt_filename = os.path.splitext(base_filename)[0] + \".txt\"\n",
    "        \n",
    "        with open(os.path.join(output_dir, txt_filename), 'w') as f:\n",
    "            f.write(\"\\n\".join(yolo_data))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {json_file_path}: {e}\")\n",
    "\n",
    "def process_dataset(dataset_path):\n",
    "    \"\"\"\n",
    "    'train'ê³¼ 'val' í´ë”ì— ëŒ€í•´ ë³€í™˜ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        json_dir = os.path.join(dataset_path, split, \"annotations\")\n",
    "        output_dir = os.path.join(dataset_path, split, \"labels\")\n",
    "\n",
    "        if not os.path.exists(json_dir):\n",
    "            print(f\"Directory not found: {json_dir}\")\n",
    "            continue\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        json_files = glob(os.path.join(json_dir, \"*.json\"))\n",
    "        print(f\"Found {len(json_files)} json files in {json_dir}\")\n",
    "\n",
    "        for json_file in tqdm(json_files, desc=f\"Converting {split} JSONs to YOLO format\"):\n",
    "            convert_to_yolo(json_file, output_dir)\n",
    "        \n",
    "        print(f\"Finished processing for {split} set. Labels are in {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29af226d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory not found: C:/Users/chobh/Desktop/ë¹…í”„ë¡œì íŠ¸/custom_dataset/train/annotations\n",
      "Directory not found: C:/Users/chobh/Desktop/ë¹…í”„ë¡œì íŠ¸/custom_dataset/val/annotations\n"
     ]
    }
   ],
   "source": [
    "# í•œë²ˆë§Œ ì‹¤í–‰\n",
    "root_path = \"C:/Users/chobh/Desktop/ë¹…í”„ë¡œì íŠ¸\"\n",
    "dataset_base_path = os.path.join(root_path, \"custom_dataset\")\n",
    "process_dataset(dataset_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc83275",
   "metadata": {},
   "source": [
    "# 3. YOLO Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a86d3c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')  # nano, ë˜ëŠ” yolov8s.pt ë“± ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ ì‚¬ìš© ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01d70dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.169 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.168 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CPU (AMD EPYC 7B13)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=./data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train15, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train15, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset 'data.yaml' error âŒ Dataset 'data.yaml' images not found, missing path '/workspace/Illegal-Parking-Detection/AI/Detection/custom_dataset/train/images'\nNote dataset download directory is '/workspace/Illegal-Parking-Detection/datasets'. You can update this in '/home/gitpod/.config/Ultralytics/settings.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages/ultralytics/engine/trainer.py:607\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myml\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    606\u001b[0m }:\n\u001b[0;32m--> 607\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages/ultralytics/data/utils.py:464\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    463\u001b[0m     m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote dataset download directory is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASETS_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You can update this in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSETTINGS_FILE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 464\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(m)\n\u001b[1;32m    465\u001b[0m t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Dataset 'data.yaml' images not found, missing path '/workspace/Illegal-Parking-Detection/AI/Detection/custom_dataset/train/images'\nNote dataset download directory is '/workspace/Illegal-Parking-Detection/datasets'. You can update this in '/home/gitpod/.config/Ultralytics/settings.json'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# í•„ìš”ì— ë”°ë¼ ì¡°ì •\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# CPUë¡œ ì„¤ì •// # GPU ì‚¬ìš©\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages/ultralytics/engine/model.py:793\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    791\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[0;32m--> 793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[1;32m    795\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages/ultralytics/engine/trainer.py:153\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m check_model_file_from_stem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(LOCAL_RANK):  \u001b[38;5;66;03m# avoid auto-downloading dataset multiple times\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Optimization utils init\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages/ultralytics/engine/trainer.py:611\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    609\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# for validating 'yolo train data=url.zip' usage\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(emojis(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclean_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m error âŒ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msingle_cls:\n\u001b[1;32m    613\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverriding class names with single class.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset 'data.yaml' error âŒ Dataset 'data.yaml' images not found, missing path '/workspace/Illegal-Parking-Detection/AI/Detection/custom_dataset/train/images'\nNote dataset download directory is '/workspace/Illegal-Parking-Detection/datasets'. You can update this in '/home/gitpod/.config/Ultralytics/settings.json'"
     ]
    }
   ],
   "source": [
    "results = model.train(\n",
    "    data=os.path.join('./data.yaml'),\n",
    "    epochs=1,       # í•„ìš”ì— ë”°ë¼ ì¡°ì •\n",
    "    imgsz=640,\n",
    "    batch=16,        # ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •\n",
    "    device=\"cpu\"        # CPUë¡œ ì„¤ì •// # GPU ì‚¬ìš©\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1196aa5",
   "metadata": {},
   "source": [
    "# 4. ëª¨ë¸ ì¶”ë¡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65549b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('runs/detect/train/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b906b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡ \n",
    "val_img_path = os.path.join(dataset_base_path, 'val/images/33_20210704_7454-0-0600.jpg')\n",
    "results = model.predict(val_img_path, save=True, conf=0.25, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67145131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ í‰ê°€\n",
    "metrics = model.val(\n",
    "    data=os.path.join(root_path, 'data.yaml'),\n",
    "    batch=16,\n",
    "    imgsz=640,\n",
    "    device=0\n",
    ")\n",
    "print(metrics)\n",
    "# map50, map50-95, precision, recall ë“± ì£¼ìš” ì§€í‘œ ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436a80b8",
   "metadata": {},
   "source": [
    "# 1. YOLOëŠ” ì°¨ëŸ‰ì„ ê°ì§€í•˜ì§€ë§Œ ê·¸ ì°¨ëŸ‰ì´ ë¶ˆë²•ì¸ì§€ëŠ” ì•ˆ ì•Œë ¤ì¤Œ\n",
    "# ë”°ë¼ì„œ ì´¬ì˜ ì‹œê°„ / ìœ„ì¹˜ / ê·œì¹™ì„ ë°”íƒ•ìœ¼ë¡œ í›„ì²˜ë¦¬ íŒë‹¨ì´ ê¼­ í•„ìš”\n",
    "# í•´ë‹¹ í•¨ìˆ˜ëŠ” ì´ëŸ¬í•œ íŒë‹¨ ë¡œì§ì„ ë‹´ë‹¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8134ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ë¶ˆë²• ì—¬ë¶€ íŒë‹¨ í•¨ìˆ˜ ì¶”ê°€\n",
    "def is_illegal_parking(location_code, timestamp_str):\n",
    "    rules = {\n",
    "        \"600\": (\"08:00\", \"20:00\"),\n",
    "        \"700\": (\"07:00\", \"22:00\"),\n",
    "    }\n",
    "\n",
    "    start_time, end_time = rules.get(location_code, (\"00:00\", \"00:00\"))\n",
    "    timestamp = datetime.strptime(timestamp_str, \"%Y%m%d_%H%M\")\n",
    "\n",
    "    start_dt = datetime.strptime(timestamp_str[:8] + \"_\" + start_time, \"%Y%m%d_%H:%M\")\n",
    "    end_dt = datetime.strptime(timestamp_str[:8] + \"_\" + end_time, \"%Y%m%d_%H:%M\")\n",
    "\n",
    "    return start_dt <= timestamp <= end_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5880c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. YOLO ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ë° ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡ \n",
    "model = YOLO('runs/detect/train/weights/best.pt')\n",
    "val_img_path = os.path.join(dataset_base_path, 'val/images/33_20210704_7454-0-0600.jpg')\n",
    "results = model.predict(val_img_path, save=True, conf=0.25, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7dc37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. íŒŒì¼ì´ë¦„ì—ì„œ ì‹œê°„ ì¶”ì¶œ í›„ íŒë‹¨\n",
    "filename = os.path.basename(val_img_path)  # ì˜ˆ: 33_20210704_7454-0-0600.jpg\n",
    "timestamp_part = filename.split('_')[1] + \"_\" + filename.split('_')[-1].split('.')[0]  # \"20210704_0600\"\n",
    "location_code = filename.split('_')[-1].split('-')[-1][:3]  # \"600\"\n",
    "\n",
    "if is_illegal_parking(location_code, timestamp_part):\n",
    "    print(\"ë¶ˆë²•ì£¼ì •ì°¨ ê°ì§€!\")\n",
    "else:\n",
    "    print(\"ì •ìƒ ì£¼ì°¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662ca07c",
   "metadata": {},
   "source": [
    "# ë¶ˆë²• ì£¼ì •ì°¨ ì‹œê°„ëŒ€ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a90439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# 1. ë¶ˆë²•ì£¼ì •ì°¨ ê·œì¹™ ë¡œë”© \n",
    "def load_restriction_rules(json_path):\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def is_illegal_parking(location_code, timestamp_str, rules_dict):\n",
    "    rule = rules_dict.get(location_code)\n",
    "    if not rule:\n",
    "        return False\n",
    "\n",
    "    start_time = rule.get(\"start_time\", \"00:00\")\n",
    "    end_time = rule.get(\"end_time\", \"00:00\")\n",
    "\n",
    "    timestamp = datetime.strptime(timestamp_str, \"%Y%m%d_%H%M\")\n",
    "    start_dt = datetime.strptime(timestamp_str[:8] + \"_\" + start_time, \"%Y%m%d_%H:%M\")\n",
    "    end_dt = datetime.strptime(timestamp_str[:8] + \"_\" + end_time, \"%Y%m%d_%H:%M\")\n",
    "\n",
    "    return start_dt <= timestamp <= end_dt\n",
    "\n",
    "#  2. ì‚¬ìš© \n",
    "#  ê²°ê³¼ ì´ë¯¸ì§€ ê²½ë¡œ\n",
    "val_img_dir = \"runs/detect/predict\"\n",
    "restriction_path = \"./restricted_areas.json\"\n",
    "rules = load_restriction_rules(restriction_path)\n",
    "\n",
    "# ê²°ê³¼ ì´ë¯¸ì§€ í•˜ë‚˜ì”© ìˆœíšŒí•˜ë©° ë¶ˆë²• ì—¬ë¶€ íŒë‹¨\n",
    "for filename in os.listdir(val_img_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        timestamp_part = filename.split('_')[1] + \"_\" + filename.split('_')[-1].split('.')[0]\n",
    "        location_code = filename.split('_')[-1].split('-')[-1][:3]\n",
    "\n",
    "        if is_illegal_parking(location_code, timestamp_part, rules):\n",
    "            print(f\" {filename}: ë¶ˆë²•ì£¼ì •ì°¨ ê°ì§€!\")\n",
    "        else:\n",
    "            print(f\" {filename}: ì •ìƒ ì£¼ì°¨\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd1f9ae",
   "metadata": {},
   "source": [
    "# ë¶ˆë²• ì£¼ì •ì°¨ ê³µíœ´ì¼ ë° ì£¼ë§ ì œì™¸ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7b4a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "# ê³µíœ´ì¼ ë¦¬ìŠ¤íŠ¸ (ì˜ˆì‹œ) - \"YYYYMMDD\" í˜•ì‹\n",
    "KOREAN_HOLIDAYS = [\n",
    "    \"20250721\",  # ì˜ˆì‹œ: 2025ë…„ 7ì›” 21ì¼\n",
    "    \"20250101\",  # ì‹ ì •\n",
    "    \"20250210\",  # ì„¤ë‚ \n",
    "    \"20250301\",  # ì‚¼ì¼ì ˆ\n",
    "    \n",
    "]\n",
    "\n",
    "# 1. JSONì—ì„œ ê·œì¹™ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "def load_restriction_rules(json_path):\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        rules = json.load(f)\n",
    "    return rules\n",
    "\n",
    "# 2. ì£¼ë§/ê³µíœ´ì¼ ì—¬ë¶€ í™•ì¸\n",
    "def is_weekend_or_holiday(timestamp):\n",
    "    date_str = timestamp.strftime(\"%Y%m%d\")\n",
    "    weekday = timestamp.weekday()  # ì›”(0) ~ ì¼(6)\n",
    "\n",
    "    return weekday >= 5 or date_str in KOREAN_HOLIDAYS\n",
    "\n",
    "# 3. íŠ¹ì • ì§€ì—­ + ì‹œê°„ì— ëŒ€í•´ ë¶ˆë²• ì—¬ë¶€ íŒë‹¨\n",
    "def is_illegal_parking(location_code, timestamp_str, rules_dict):\n",
    "    rule = rules_dict.get(location_code)\n",
    "    if not rule:\n",
    "        return False  # ë“±ë¡ë˜ì§€ ì•Šì€ ì§€ì—­ì€ ë¶ˆë²• ì•„ë‹˜ ì²˜ë¦¬\n",
    "\n",
    "    start_time = rule.get(\"start_time\", \"00:00\")\n",
    "    end_time = rule.get(\"end_time\", \"00:00\")\n",
    "\n",
    "    timestamp = datetime.strptime(timestamp_str, \"%Y%m%d_%H%M\")\n",
    "    \n",
    "    #  ì£¼ë§/ê³µíœ´ì¼ì€ ë¶ˆë²• ì•„ë‹˜ ì²˜ë¦¬\n",
    "    if is_weekend_or_holiday(timestamp):\n",
    "        return False\n",
    "\n",
    "    start_dt = datetime.strptime(timestamp_str[:8] + \"_\" + start_time, \"%Y%m%d_%H:%M\")\n",
    "    end_dt = datetime.strptime(timestamp_str[:8] + \"_\" + end_time, \"%Y%m%d_%H:%M\")\n",
    "\n",
    "    return start_dt <= timestamp <= end_dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7617b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON ê²½ë¡œ\n",
    "restriction_path = \"./restricted_areas.json\"\n",
    "rules = load_restriction_rules(restriction_path)\n",
    "\n",
    "# ì˜ˆì‹œ íŒŒì¼ëª…: 33_20250721_7454-0-0600.jpg\n",
    "filename = os.path.basename(val_img_path)\n",
    "timestamp_part = filename.split('_')[1] + \"_\" + filename.split('_')[-1].split('.')[0]  # \"20250721_0600\"\n",
    "location_code = filename.split('_')[-1].split('-')[-1][:3]  # \"600\"\n",
    "\n",
    "# íŒë‹¨\n",
    "if is_illegal_parking(location_code, timestamp_part, rules):\n",
    "    print(\"ë¶ˆë²•ì£¼ì •ì°¨ ê°ì§€!\")\n",
    "else:\n",
    "    print(\"ì •ìƒ ì£¼ì°¨ ë˜ëŠ” ì˜ˆì™¸ì¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9cb4f7",
   "metadata": {},
   "source": [
    "# ì¢Œí‘œë¥¼ ë„ë¡œëª…ì£¼ì†Œë¡œ ë³€í™˜ / Kakaoì—ì„œ Rest api "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da66b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. ì¢Œí‘œ â†’ ì£¼ì†Œ (ë„ë¡œëª…ì£¼ì†Œ + í–‰ì •ì½”ë“œ) ë³€í™˜\n",
    "def reverse_geocode_kakao(x, y, api_key):\n",
    "    url = \"https://dapi.kakao.com/v2/local/geo/coord2address.json\"\n",
    "    headers = {\"Authorization\": f\"KakaoAK {api_key}\"}\n",
    "    params = {\"x\": x, \"y\": y}\n",
    "    \n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        documents = response.json().get(\"documents\")\n",
    "        if documents:\n",
    "            address_info = documents[0][\"road_address\"]\n",
    "            road_name = address_info[\"address_name\"]\n",
    "            b_code = documents[0][\"address\"][\"b_code\"]  # í–‰ì •ë™ ì½”ë“œ\n",
    "            return road_name, b_code\n",
    "    return None, None\n",
    "\n",
    "# 2. ë„ë¡œëª…ì£¼ì†Œ + í–‰ì •ì½”ë“œ â†’ location_code ì¶”ì¶œ\n",
    "def load_area_mapping(json_path=\"./area_mapping.json\"):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "AREA_MAPPING = load_area_mapping()\n",
    "\n",
    "def get_location_code(road_name, admin_code):\n",
    "    info = AREA_MAPPING.get(road_name)\n",
    "    if info and info.get(\"admin_code\") == admin_code:\n",
    "        return info.get(\"location_code\")\n",
    "    return None\n",
    "\n",
    "# 3. location_code â†’ ì‹œê°„ ê¸°ë°˜ ë¶ˆë²• ì—¬ë¶€ íŒë‹¨\n",
    "def load_restricted_areas(json_path=\"./restricted_areas.json\"):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "RESTRICTED_AREAS = load_restricted_areas()\n",
    "\n",
    "def is_illegal_parking(location_code, current_time):\n",
    "    location_info = RESTRICTED_AREAS.get(location_code)\n",
    "    if not location_info:\n",
    "        return False  # ì œí•œ êµ¬ì—­ ì•„ë‹˜\n",
    "\n",
    "    day_name = current_time.strftime('%A').lower()\n",
    "    now_time = current_time.time()\n",
    "    time_range = location_info[\"restricted_times\"].get(day_name)\n",
    "\n",
    "    if not time_range:\n",
    "        return False\n",
    "\n",
    "    start_time = datetime.strptime(time_range[\"start\"], \"%H:%M\").time()\n",
    "    end_time = datetime.strptime(time_range[\"end\"], \"%H:%M\").time()\n",
    "    return start_time <= now_time <= end_time\n",
    "\n",
    "# 4. ì „ì²´ íë¦„: YOLO ì¢Œí‘œ â†’ ë¶ˆë²• ì—¬ë¶€ íŒë‹¨\n",
    "def process_detection(x, y, api_key):\n",
    "    road_name, admin_code = reverse_geocode_kakao(x, y, api_key)\n",
    "    if not road_name or not admin_code:\n",
    "        return False, \"ì£¼ì†Œ ë³€í™˜ ì‹¤íŒ¨\"\n",
    "\n",
    "    location_code = get_location_code(road_name, admin_code)\n",
    "    if not location_code:\n",
    "        return False, \"location_code ë§¤í•‘ ì‹¤íŒ¨\"\n",
    "\n",
    "    now = datetime.now()\n",
    "    if is_illegal_parking(location_code, now):\n",
    "        return True, f\"ë¶ˆë²• ì£¼ì •ì°¨ (ìœ„ì¹˜: {road_name})\"\n",
    "    else:\n",
    "        return False, f\"í•©ë²• ì£¼ì •ì°¨ (ìœ„ì¹˜: {road_name})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f8073",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    API_KEY = \"YOUR_KAKAO_REST_API_KEY\"  # ì‹¤ì œ ì¹´ì¹´ì˜¤ REST API í‚¤ë¡œ ëŒ€ì²´\n",
    "    x, y = 127.0276, 37.4979  # ì˜ˆ: ê°•ë‚¨ì—­ ê·¼ì²˜ ì¢Œí‘œ\n",
    "\n",
    "    result, message = process_detection(x, y, API_KEY)\n",
    "    print(message)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
