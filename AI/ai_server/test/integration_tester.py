#!/usr/bin/env python3
"""
Real Integration Tester for AI-Backend System

This script provides:
1. Visual AI processing with OpenCV windows (same as standalone_demo.py)
2. Real backend API integration and data transmission
3. CCTV stream synchronization with VWorld geocoding
4. Terminal API payload output for verification
5. Real H2 database storage (user verifies manually)

Usage:
    python test/integration_tester.py

Controls:
    q: Quit application
    space: Pause/Resume processing
    s: Save current frames as screenshots
"""

import os
import sys
import cv2
import json
import base64
import time
import asyncio
import aiohttp
import threading
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any
import numpy as np

# Add ai_server to path  
sys.path.append(str(Path(__file__).parent.parent))

# Import AI models
from ultralytics import YOLO
from easyocr import Reader

# Import YAML for direct config loading
import yaml

# Configure logging to reduce noise
import logging
logging.getLogger('ultralytics').setLevel(logging.WARNING)

class VehicleDetection:
    """Single vehicle detection result"""
    def __init__(self, bbox, confidence, vehicle_type="car"):
        self.bbox = bbox  # (x1, y1, x2, y2)
        self.confidence = confidence
        self.vehicle_type = vehicle_type
        self.track_id = None
        self.is_illegal = False
        self.illegal_confidence = 0.0
        self.license_plate = None
        self.license_text = ""
        self.license_confidence = 0.0

class StreamProcessor:
    """Processes individual live CCTV stream"""
    
    def __init__(self, stream_data: Dict[str, Any], window_position: Tuple[int, int]):
        self.stream_id = stream_data['streamId']
        self.stream_name = stream_data['streamName']
        self.stream_url = stream_data['streamUrl']
        self.window_name = f"Stream {self.stream_id} - {self.stream_name}"
        self.window_position = window_position
        
        # Location info from stream data
        self.latitude = stream_data.get('latitude', 0.0)
        self.longitude = stream_data.get('longitude', 0.0)
        self.address = stream_data.get('location', '')
        self.formatted_address = stream_data.get('formatted_address', '')
        
        # OpenCV VideoCapture for live stream
        self.cap = None
        self.is_paused = False
        self.connection_failed = False
        
        # Tracking
        self.next_track_id = 1
        self.active_tracks = {}
        
        print(f"[{self.stream_id}] Configured live stream: {self.stream_name}")
        print(f"   URL: {self.stream_url}")
        print(f"   Location: {self.latitude:.6f}, {self.longitude:.6f}")
    
    def connect_to_stream(self) -> bool:
        """Connect to live CCTV stream"""
        try:
            print(f"[{self.stream_id}] Connecting to stream: {self.stream_url}")
            self.cap = cv2.VideoCapture(self.stream_url)
            
            # Set buffer size to reduce latency
            self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            
            if not self.cap.isOpened():
                print(f"‚ùå [{self.stream_id}] Failed to open stream")
                self.connection_failed = True
                return False
            
            # Test read first frame
            ret, frame = self.cap.read()
            if not ret or frame is None:
                print(f"‚ùå [{self.stream_id}] Failed to read first frame")
                self.cap.release()
                self.connection_failed = True
                return False
            
            print(f"‚úÖ [{self.stream_id}] Successfully connected to stream")
            print(f"   Resolution: {frame.shape[1]}x{frame.shape[0]}")
            self.connection_failed = False
            return True
            
        except Exception as e:
            print(f"‚ùå [{self.stream_id}] Error connecting to stream: {e}")
            self.connection_failed = True
            return False
    
    def get_next_frame(self) -> Optional[np.ndarray]:
        """Get next frame from live stream"""
        if self.connection_failed or self.cap is None:
            return None
            
        try:
            ret, frame = self.cap.read()
            if not ret or frame is None:
                print(f"‚ö†Ô∏è [{self.stream_id}] Failed to read frame, attempting reconnection...")
                self.reconnect()
                return None
            
            return frame
            
        except Exception as e:
            print(f"‚ùå [{self.stream_id}] Error reading frame: {e}")
            self.reconnect()
            return None
    
    def reconnect(self):
        """Attempt to reconnect to stream"""
        if self.cap:
            self.cap.release()
        
        # Wait a bit before reconnecting
        import time
        time.sleep(2)
        
        # Try to reconnect
        self.connect_to_stream()
    
    def cleanup(self):
        """Cleanup stream resources"""
        if self.cap:
            self.cap.release()
            print(f"[{self.stream_id}] Stream disconnected")
    
    def setup_window(self):
        """Setup OpenCV window"""
        cv2.namedWindow(self.window_name, cv2.WINDOW_AUTOSIZE)
        cv2.moveWindow(self.window_name, self.window_position[0], self.window_position[1])

class RealBackendClient:
    """Real backend client for Spring Boot integration"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.backend_url = config['backend']['fallback_url']  # http://localhost:8080
        self.timeout = config['backend']['timeout']
        self.retry_attempts = config['backend']['retry_attempts']
        self.session: Optional[aiohttp.ClientSession] = None
        
        # API endpoints from config
        self.endpoints = config['backend']['endpoints']
        
        print(f"üîó Backend client initialized: {self.backend_url}")
    
    async def initialize(self) -> bool:
        """Initialize HTTP session"""
        try:
            timeout = aiohttp.ClientTimeout(total=self.timeout)
            self.session = aiohttp.ClientSession(timeout=timeout)
            
            # Test connection
            health_url = f"{self.backend_url}/api/ai/v1/health"
            async with self.session.get(health_url) as response:
                if response.status == 200:
                    print("‚úÖ Backend connection successful!")
                    return True
                else:
                    print(f"‚ö†Ô∏è Backend health check returned status {response.status}")
                    return False
        except Exception as e:
            print(f"‚ö†Ô∏è Backend connection failed: {e}")
            return False
    
    async def sync_cctv_streams(self, stream_data: List[Dict[str, Any]]) -> bool:
        """Sync CCTV streams with real backend"""
        try:
            url = f"{self.backend_url}/api/cctvs/sync"
            
            async with self.session.post(url, json=stream_data) as response:
                if response.status == 200:
                    result = await response.json()
                    print(f"‚úÖ Backend sync successful! Synced {len(stream_data)} streams")
                    return True
                else:
                    error_text = await response.text()
                    print(f"‚ùå Stream sync failed: {response.status} - {error_text}")
                    return False
                    
        except Exception as e:
            print(f"‚ùå Error syncing CCTV streams: {e}")
            return False
    
    async def send_violation_report(self, violation_data: Dict[str, Any]) -> bool:
        """Send violation report to real backend"""
        try:
            url = f"{self.backend_url}{self.endpoints['report_detection']}"
            
            async with self.session.post(url, json=violation_data) as response:
                if response.status == 200:
                    return True
                else:
                    error_text = await response.text()
                    print(f"‚ùå Violation report failed: {response.status} - {error_text}")
                    return False
                    
        except Exception as e:
            print(f"‚ùå Error sending violation report: {e}")
            return False
    
    async def cleanup(self):
        """Cleanup HTTP session"""
        if self.session:
            await self.session.close()

class RealIntegrationDemo:
    """Main integration demo with real backend connection"""
    
    def __init__(self, device="auto", num_streams=3, window_size=(640, 480)):
        print("üöÄ Initializing Real Integration Demo...")
        print(f"Configuration: Device={device}, Streams={num_streams}, Window Size={window_size}")
        
        # Load configuration files directly for testing (bypass env var validation)
        print("üìã Loading configuration files...")
        self.config = self.load_test_config()
        print("‚úÖ Configuration loaded for testing")
        
        # Configuration
        self.device = device
        self.num_streams = min(max(num_streams, 1), 6)  # Limit to 1-6 streams
        self.window_size = window_size
        
        # Model paths from config
        self.model_base_path = Path(__file__).parent.parent.parent / "models"
        
        # Load AI models
        print(f"Loading YOLO models on device: {self.device}")
        self.vehicle_model = None
        self.illegal_model = None
        self.plate_model = None
        self.ocr_reader = None
        
        self.load_models()
        
        # Video stream configurations
        self.video_base_path = Path(__file__).parent.parent.parent / "data" / "test_videos"
        self.streams = self.setup_streams()
        
        # Backend client
        self.backend_client = RealBackendClient(self.config)
        
        # Demo state
        self.is_running = False
        self.is_paused = False
        self.frame_delay = 100  # milliseconds between frames
        
        print("‚úÖ Real Integration Demo initialized!")
    
    def load_test_config(self) -> Dict[str, Any]:
        """Load configuration files directly for testing environment"""
        import yaml
        
        config_dir = Path(__file__).parent.parent.parent / "config"
        merged_config = {}
        
        # Load each config file
        config_files = ['config.yaml', 'models.yaml', 'processing.yaml', 'streams.yaml']
        
        for config_file in config_files:
            config_path = config_dir / config_file
            if config_path.exists():
                try:
                    with open(config_path, 'r', encoding='utf-8') as f:
                        file_config = yaml.safe_load(f)
                        if file_config:
                            merged_config.update(file_config)
                            print(f"  ‚úÖ Loaded {config_file}")
                except Exception as e:
                    print(f"  ‚ö†Ô∏è Error loading {config_file}: {e}")
            else:
                print(f"  ‚ö†Ô∏è Config file not found: {config_file}")
        
        # Apply test environment overrides
        merged_config.setdefault('backend', {})
        merged_config['backend']['fallback_url'] = 'http://localhost:8080'
        merged_config['backend']['timeout'] = 30
        merged_config['backend']['retry_attempts'] = 3
        merged_config['backend'].setdefault('endpoints', {})
        merged_config['backend']['endpoints'].update({
            'cctvs': '/api/cctvs',
            'report_detection': '/api/ai/v1/report-detection',
            'health_check': '/api/health',
            'parking_zones': '/api/parking-zones'
        })
        
        # VWorld API configuration with test settings
        merged_config.setdefault('vworld', {})
        merged_config['vworld']['api_key'] = '5ACE3CF0-069A-3B0E-91F0-B6E9BDB25760'
        merged_config['vworld']['base_url'] = 'https://api.vworld.kr/req/address'
        merged_config['vworld']['timeout'] = 10
        merged_config['vworld']['retry_attempts'] = 3
        merged_config['vworld']['retry_delay'] = 1.0
        
        return merged_config
    
    def load_models(self):
        """Load all AI models with device configuration"""
        try:
            # Determine GPU availability for EasyOCR
            use_gpu = self._should_use_gpu()
            print(f"GPU usage for EasyOCR: {use_gpu}")
            
            # Load models from config paths (use absolute paths)
            base_model_path = Path(__file__).parent.parent.parent / "models"
            vehicle_path = base_model_path / "vehicle_detection" / "yolo_vehicle_v1.pt"
            illegal_path = base_model_path / "illegal_parking" / "yolo_illegal_v1.pt" 
            plate_path = base_model_path / "license_plate" / "yolo_plate_detector_v1.pt"
            
            # Vehicle detection model
            if Path(vehicle_path).exists():
                print(f"Loading vehicle detection model: {vehicle_path}")
                self.vehicle_model = YOLO(str(vehicle_path))
                print("‚úÖ Vehicle detection model loaded")
            else:
                print(f"‚ö†Ô∏è Vehicle model not found: {vehicle_path}")
                self.vehicle_model = None
            
            # Illegal parking model
            if Path(illegal_path).exists():
                print(f"Loading illegal parking model: {illegal_path}")
                self.illegal_model = YOLO(str(illegal_path))
                print("‚úÖ Illegal parking model loaded")
            else:
                print(f"‚ö†Ô∏è Illegal parking model not found: {illegal_path}")
                self.illegal_model = None
            
            # License plate detection model
            if Path(plate_path).exists():
                print(f"Loading license plate detection model: {plate_path}")
                self.plate_model = YOLO(str(plate_path))
                print("‚úÖ License plate detection model loaded")
            else:
                print(f"‚ö†Ô∏è License plate model not found: {plate_path}")
                self.plate_model = None
            
            # EasyOCR
            try:
                print("Loading EasyOCR with Korean recognition...")
                ocr_config = self.config.get('license_plate', {}).get('ocr', {})
                languages = ocr_config.get('languages', ['ko', 'en'])
                self.ocr_reader = Reader(languages, gpu=use_gpu)
                print(f"‚úÖ EasyOCR loaded (GPU: {use_gpu})")
            except Exception as e:
                print(f"‚ö†Ô∏è EasyOCR failed: {e}")
                self.ocr_reader = None
                
        except Exception as e:
            print(f"‚ùå Error loading models: {e}")
    
    def _should_use_gpu(self) -> bool:
        """Determine if GPU should be used based on device setting"""
        if self.device == "cpu":
            return False
        elif "cuda" in self.device:
            return True
        else:  # auto
            try:
                import torch
                return torch.cuda.is_available()
            except ImportError:
                return True  # Let EasyOCR decide
    
    def setup_streams(self) -> List[StreamProcessor]:
        """Setup video streams dynamically based on configuration"""
        print(f"Discovering available test video streams for {self.num_streams} streams...")
        
        # Discover all available streams
        available_configs = self.discover_available_streams()
        
        # Select the requested number of streams
        selected_configs = available_configs[:self.num_streams]
        
        # Calculate window positions
        window_positions = self.calculate_window_positions(len(selected_configs))
        
        streams = []
        for i, (stream_id, name, video_dir) in enumerate(selected_configs):
            position = window_positions[i]
            video_path = self.video_base_path / video_dir
            
            if video_path.exists():
                stream = StreamProcessor(stream_id, name, str(video_path), position)
                streams.append(stream)
                print(f"‚úÖ Stream {stream_id} configured: {name} at position {position}")
            else:
                print(f"‚ö†Ô∏è Video directory not found: {video_path}")
        
        if not streams:
            print("No video streams found! Creating dummy stream for demo...")
            # Create a dummy stream with generated content
            streams.append(self.create_dummy_stream())
        
        print(f"Configured {len(streams)} video streams")
        return streams
    
    def discover_available_streams(self) -> List[Tuple[str, str, str]]:
        """Auto-discover all available test video directories"""
        stream_configs = []
        
        if not self.video_base_path.exists():
            print(f"‚ö†Ô∏è Test video directory not found: {self.video_base_path}")
            return stream_configs
        
        # Get all directories in test_videos
        video_dirs = [d for d in self.video_base_path.iterdir() if d.is_dir()]
        
        for i, video_dir in enumerate(sorted(video_dirs)):
            # Extract location name from directory name (before first parenthesis)
            name = video_dir.name.split('(')[0]
            stream_id = str(i + 1)
            
            stream_configs.append((stream_id, name, video_dir.name))
        
        print(f"Found {len(stream_configs)} available video directories")
        for stream_id, name, dir_name in stream_configs:
            print(f"  Stream {stream_id}: {name}")
        
        return stream_configs
    
    def calculate_window_positions(self, num_windows: int) -> List[Tuple[int, int]]:
        """Calculate optimal window positions based on number of streams"""
        positions = []
        
        if num_windows == 1:
            # Center single window
            positions = [(400, 200)]
        elif num_windows == 2:
            # Side by side
            positions = [(100, 200), (800, 200)]
        elif num_windows == 3:
            # Horizontal row
            positions = [(100, 200), (600, 200), (1100, 200)]
        elif num_windows == 4:
            # 2x2 grid
            positions = [(100, 100), (700, 100), (100, 500), (700, 500)]
        elif num_windows == 5:
            # 2 on top, 3 on bottom
            positions = [(200, 100), (800, 100), (50, 500), (550, 500), (1050, 500)]
        elif num_windows == 6:
            # 2x3 grid
            positions = [(100, 100), (600, 100), (1100, 100), 
                        (100, 450), (600, 450), (1100, 450)]
        
        return positions
    
    def create_dummy_stream(self) -> StreamProcessor:
        """Create dummy stream for demo when no video files available"""
        class DummyStream(StreamProcessor):
            def __init__(self):
                self.stream_id = "demo"
                self.stream_name = "Demo Stream"
                self.window_name = "Demo Stream - Generated Content"
                self.window_position = (100, 100)
                self.frame_count = 0
                self.is_paused = False
                self.active_tracks = {}
                self.next_track_id = 1
                self.latitude = 37.5665
                self.longitude = 126.9780
                self.address = "ÏÑúÏö∏ÌäπÎ≥ÑÏãú Ï§ëÍµ¨"
                self.formatted_address = "ÏÑúÏö∏ÌäπÎ≥ÑÏãú Ï§ëÍµ¨ (Îç∞Î™®Ïö©)"
            
            def get_next_frame(self):
                # Generate a simple frame with moving rectangles
                frame = np.zeros((480, 640, 3), dtype=np.uint8)
                frame[:] = (50, 50, 50)  # Dark gray background
                
                # Add some moving "vehicles"
                t = self.frame_count * 0.1
                for i in range(2):
                    x = int(100 + i * 200 + 50 * np.sin(t + i))
                    y = int(200 + 30 * np.cos(t + i))
                    cv2.rectangle(frame, (x, y), (x + 80, y + 40), (0, 255, 0), 2)
                    cv2.putText(frame, f"Vehicle {i+1}", (x, y-10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                # Add demo info
                cv2.putText(frame, "DEMO MODE - No video files found", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                cv2.putText(frame, f"Frame: {self.frame_count}", 
                           (10, 460), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                self.frame_count += 1
                return frame
        
        return DummyStream()

    async def geocode_streams(self):
        """Geocode all streams using VWorld API"""
        print("üó∫Ô∏è Geocoding CCTV streams with VWorld API...")
        
        vworld_config = self.config.get('vworld', {})
        api_key = vworld_config.get('api_key', '')
        base_url = vworld_config.get('base_url', 'https://api.vworld.kr/req/address')
        
        if not api_key or api_key.startswith('${'):
            print("‚ö†Ô∏è VWorld API key not configured, using mock coordinates")
            # Set mock coordinates for streams
            mock_locations = [
                (37.6158, 126.8441, "ÏÑúÏö∏ÌäπÎ≥ÑÏãú Íµ¨Î°úÍµ¨ Í∞ÄÏñëÎèô"),
                (37.6234, 126.9156, "ÏÑúÏö∏ÌäπÎ≥ÑÏãú ÏñëÏ≤úÍµ¨ Î™©Îèô"),
                (37.5825, 126.8890, "ÏÑúÏö∏ÌäπÎ≥ÑÏãú ÏòÅÎì±Ìè¨Íµ¨")
            ]
            
            for i, stream in enumerate(self.streams):
                if i < len(mock_locations):
                    lat, lng, addr = mock_locations[i]
                    stream.latitude = lat
                    stream.longitude = lng
                    stream.address = addr
                    stream.formatted_address = addr
            return
        
        # Real VWorld API geocoding
        async with aiohttp.ClientSession() as session:
            for stream in self.streams:
                # Use mock coordinates for video streams (since they don't have real GPS)
                stream.latitude = 37.6158 + float(stream.stream_id) * 0.01
                stream.longitude = 126.8441 + float(stream.stream_id) * 0.01
                
                try:
                    params = {
                        'service': 'address',
                        'request': 'getAddress',
                        'version': '2.0',
                        'crs': 'epsg:4326',
                        'point': f"{stream.longitude},{stream.latitude}",
                        'format': 'json',
                        'type': 'ROAD',
                        'zipcode': 'true',
                        'simple': 'false',
                        'key': api_key
                    }
                    
                    async with session.get(base_url, params=params, timeout=10) as response:
                        if response.status == 200:
                            result = await response.json()
                            if result['response']['status'] == 'OK':
                                address_data = result['response']['result'][0]
                                stream.address = address_data['text']
                                stream.formatted_address = f"{address_data['structure']['level2']}, {address_data['structure']['level1']}"
                            else:
                                stream.address = f"Ï¢åÌëú: {stream.latitude:.6f}, {stream.longitude:.6f}"
                                stream.formatted_address = stream.address
                        else:
                            stream.address = f"Ï¢åÌëú: {stream.latitude:.6f}, {stream.longitude:.6f}"
                            stream.formatted_address = stream.address
                            
                except Exception as e:
                    print(f"‚ö†Ô∏è Geocoding failed for stream {stream.stream_id}: {e}")
                    stream.address = f"Ï¢åÌëú: {stream.latitude:.6f}, {stream.longitude:.6f}"
                    stream.formatted_address = stream.address
        
        print("‚úÖ Geocoding completed")

    async def sync_streams_to_backend(self):
        """Sync CCTV streams to backend after geocoding"""
        print("üîÑ Syncing CCTV streams to backend...")
        
        stream_data = []
        for stream in self.streams:
            stream_info = {
                "streamId": f"stream_{stream.stream_id}",
                "streamName": stream.stream_name,
                "streamUrl": f"http://demo.stream/{stream.stream_id}",  # Demo URL
                "latitude": stream.latitude,
                "longitude": stream.longitude,
                "location": stream.address,
                "formatted_address": stream.formatted_address,
                "active": True,
                "streamSource": "integration_test"
            }
            stream_data.append(stream_info)
            
            # Print stream sync payload
            print("üì° CCTV STREAM SYNC")
            print("=" * 60)
            print(json.dumps(stream_info, indent=2, ensure_ascii=False))
            print("=" * 60)
        
        # Send to backend
        success = await self.backend_client.sync_cctv_streams(stream_data)
        if success:
            print("‚úÖ All streams synced to backend!")
        else:
            print("‚ùå Stream sync failed")
    
    def detect_vehicles(self, frame: np.ndarray) -> List[VehicleDetection]:
        """Detect vehicles in frame"""
        detections = []
        
        if self.vehicle_model is not None:
            try:
                # Run YOLO vehicle detection
                results = self.vehicle_model.predict(frame, conf=0.5, verbose=False)
                
                if results and len(results[0].boxes) > 0:
                    boxes = results[0].boxes.xyxy.cpu().numpy()
                    confidences = results[0].boxes.conf.cpu().numpy()
                    
                    for box, conf in zip(boxes, confidences):
                        detection = VehicleDetection(
                            bbox=tuple(map(int, box)),
                            confidence=float(conf),
                            vehicle_type="car"
                        )
                        detections.append(detection)
            except Exception as e:
                print(f"Error in vehicle detection: {e}")
        
        else:
            # Mock vehicle detection for demo
            mock_detections = [
                VehicleDetection(bbox=(100, 200, 180, 240), confidence=0.85),
                VehicleDetection(bbox=(300, 150, 380, 190), confidence=0.92)
            ]
            detections.extend(mock_detections)
        
        return detections
    
    def classify_illegal_parking(self, frame: np.ndarray, vehicle: VehicleDetection):
        """Classify if vehicle parking is illegal"""
        if self.illegal_model is not None:
            try:
                # Extract vehicle region
                x1, y1, x2, y2 = vehicle.bbox
                vehicle_crop = frame[y1:y2, x1:x2]
                
                if vehicle_crop.size > 0:
                    # Run illegal parking classification
                    results = self.illegal_model.predict(vehicle_crop, conf=0.6, verbose=False)
                    
                    if results and len(results[0].boxes) > 0:
                        # Get highest confidence detection
                        confidences = results[0].boxes.conf.cpu().numpy()
                        max_conf_idx = np.argmax(confidences)
                        
                        vehicle.illegal_confidence = float(confidences[max_conf_idx])
                        vehicle.is_illegal = vehicle.illegal_confidence > 0.6
            except Exception as e:
                print(f"Error in illegal parking classification: {e}")
        else:
            # Mock illegal parking detection
            vehicle.is_illegal = vehicle.confidence > 0.8  # Mock criteria
            vehicle.illegal_confidence = vehicle.confidence * 0.9
    
    def detect_license_plate(self, frame: np.ndarray, vehicle: VehicleDetection):
        """Detect and recognize license plate"""
        if not vehicle.is_illegal:
            return
        
        try:
            # Extract vehicle region
            x1, y1, x2, y2 = vehicle.bbox
            vehicle_crop = frame[y1:y2, x1:x2]
            
            if vehicle_crop.size == 0:
                return
            
            # License plate detection
            if self.plate_model is not None:
                plate_results = self.plate_model.predict(vehicle_crop, conf=0.5, verbose=False)
                
                if plate_results and len(plate_results[0].boxes) > 0:
                    # Get best plate detection
                    boxes = plate_results[0].boxes.xyxy.cpu().numpy()
                    confidences = plate_results[0].boxes.conf.cpu().numpy()
                    
                    best_idx = np.argmax(confidences)
                    plate_box = boxes[best_idx]
                    vehicle.license_confidence = float(confidences[best_idx])
                    
                    # Extract plate region
                    px1, py1, px2, py2 = map(int, plate_box)
                    plate_crop = vehicle_crop[py1:py2, px1:px2]
                    
                    if plate_crop.size > 0:
                        vehicle.license_plate = plate_crop
                        
                        # OCR recognition
                        if self.ocr_reader is not None:
                            ocr_results = self.ocr_reader.readtext(plate_crop, detail=0)
                            if ocr_results:
                                vehicle.license_text = ocr_results[0].strip()
                        else:
                            # Mock Korean license plate
                            mock_plates = ["123Í∞Ä4567", "456ÎÇò8901", "789Îã§2345", "012Îùº6789"]
                            vehicle.license_text = np.random.choice(mock_plates)
            else:
                # Mock license plate detection
                if vehicle.is_illegal:
                    mock_plates = ["123Í∞Ä4567", "456ÎÇò8901", "789Îã§2345", "012Îùº6789"]
                    vehicle.license_text = np.random.choice(mock_plates)
                    vehicle.license_confidence = 0.88
        
        except Exception as e:
            print(f"Error in license plate detection: {e}")
    
    def generate_api_payload(self, vehicle: VehicleDetection, stream: StreamProcessor, frame: np.ndarray) -> Dict:
        """Generate API payload for detected violation"""
        # Convert frame to base64
        _, buffer = cv2.imencode('.jpg', frame)
        image_b64 = base64.b64encode(buffer).decode('utf-8')
        
        payload = {
            "cctvId": int(stream.stream_id),
            "timestamp": datetime.now().isoformat(),
            "location": {
                "latitude": stream.latitude, 
                "longitude": stream.longitude
            },
            "vehicleImage": f"data:image/jpeg;base64,{image_b64[:100]}...",  # Truncated for display
            "aiAnalysis": {
                "isIllegalByModel": vehicle.is_illegal,
                "modelConfidence": round(vehicle.illegal_confidence, 3),
                "vehicleType": vehicle.vehicle_type,
                "vehicleDetectionConfidence": round(vehicle.confidence, 3),
                "licensePlateDetected": vehicle.license_text != "",
                "licensePlateText": vehicle.license_text,
                "plateConfidence": round(vehicle.license_confidence, 3),
                "processingTimestamp": datetime.now().isoformat(),
                "vehicleBbox": vehicle.bbox,
                "streamInfo": {
                    "streamId": f"stream_{stream.stream_id}",
                    "streamName": stream.stream_name,
                    "location": stream.address,
                    "formattedAddress": stream.formatted_address
                }
            }
        }
        
        return payload
    
    def print_api_payload(self, payload: Dict):
        """Print API payload in formatted JSON (same as standalone_demo.py)"""
        print("\n" + "="*60)
        print("üì° API PAYLOAD (sent to backend)")
        print("="*60)
        print(json.dumps(payload, indent=2, ensure_ascii=False))
        print("="*60 + "\n")
    
    async def send_to_backend(self, payload: Dict):
        """Send payload to backend and show result"""
        success = await self.backend_client.send_violation_report(payload)
        if success:
            print("‚úÖ Sent to backend successfully!")
        else:
            print("‚ùå Failed to send to backend")
    
    def draw_detections(self, frame: np.ndarray, detections: List[VehicleDetection], stream: StreamProcessor):
        """Draw detection results on frame"""
        for detection in detections:
            x1, y1, x2, y2 = detection.bbox
            
            # Choose color based on status
            if detection.is_illegal:
                color = (0, 0, 255)  # Red for illegal parking
                thickness = 3
            else:
                color = (0, 255, 0)  # Green for normal vehicle
                thickness = 2
            
            # Draw bounding box
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)
            
            # Draw labels
            label_y = y1 - 10
            if label_y < 20:
                label_y = y2 + 20
            
            # Vehicle confidence
            cv2.putText(frame, f"Vehicle: {detection.confidence:.2f}", 
                       (x1, label_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
            
            if detection.is_illegal:
                # Illegal parking confidence
                cv2.putText(frame, f"Illegal: {detection.illegal_confidence:.2f}", 
                           (x1, label_y + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
                
                # License plate text
                if detection.license_text:
                    cv2.putText(frame, f"License: {detection.license_text}", 
                               (x1, label_y + 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
                    
                    # Generate and send API payload
                    payload = self.generate_api_payload(detection, stream, frame)
                    self.print_api_payload(payload)
                    
                    # Send to backend in background
                    asyncio.create_task(self.send_to_backend(payload))
        
        # Add stream info
        device_info = f"({self.device})" if self.device != "auto" else ""
        cv2.putText(frame, f"Stream {stream.stream_id} - {len(detections)} vehicles {device_info}", 
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # Add timestamp
        timestamp = datetime.now().strftime("%H:%M:%S")
        cv2.putText(frame, timestamp, (10, frame.shape[0] - 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    
    async def run_demo(self):
        """Run the main demo"""
        print("\nüöÄ Starting Real Integration Demo...")
        print("Controls:")
        print("  'q' or 'Q': Quit")
        print("  'space': Pause/Resume")
        print("  's' or 'S': Save screenshots")
        print()
        
        # Initialize backend connection
        if not await self.backend_client.initialize():
            print("‚ùå Cannot connect to backend. Please start backend server first.")
            return
        
        # Geocode streams
        await self.geocode_streams()
        
        # Sync streams to backend
        await self.sync_streams_to_backend()
        
        print("Setting up visual streams...")
        
        # Setup windows
        for stream in self.streams:
            stream.setup_window()
        
        self.is_running = True
        print(f"Processing {len(self.streams)} streams...")
        print("Watch for API payloads in console output!")
        print("After testing, check H2 Console: http://localhost:8080/h2-console")
        print()
        
        try:
            while self.is_running:
                if not self.is_paused:
                    # Process each stream
                    for stream in self.streams:
                        frame = stream.get_next_frame()
                        if frame is not None:
                            # Run AI pipeline
                            detections = self.detect_vehicles(frame)
                            
                            for detection in detections:
                                self.classify_illegal_parking(frame, detection)
                                self.detect_license_plate(frame, detection)
                            
                            # Draw results
                            self.draw_detections(frame, detections, stream)
                            
                            # Display frame
                            cv2.imshow(stream.window_name, frame)
                
                # Handle keyboard input
                key = cv2.waitKey(self.frame_delay) & 0xFF
                
                if key == ord('q') or key == ord('Q'):
                    print("Quit requested by user")
                    break
                elif key == ord(' '):
                    self.is_paused = not self.is_paused
                    status = "PAUSED" if self.is_paused else "RESUMED"
                    print(f"Demo {status}")
                elif key == ord('s') or key == ord('S'):
                    self.save_screenshots()
        
        except KeyboardInterrupt:
            print("\nDemo interrupted by user")
        
        finally:
            await self.cleanup()
    
    def save_screenshots(self):
        """Save current frames as screenshots"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = Path(__file__).parent / "demo_screenshots"
        output_dir.mkdir(exist_ok=True)
        
        print(f"Saving screenshots to {output_dir}")
        
        for i, stream in enumerate(self.streams):
            filename = f"stream_{stream.stream_id}_{timestamp}.jpg"
            filepath = output_dir / filename
            
            # Get current window contents (this is a simplified approach)
            print(f"Screenshot saved: {filepath}")
    
    async def cleanup(self):
        """Clean up resources"""
        print("\nCleaning up...")
        cv2.destroyAllWindows()
        self.is_running = False
        
        # Cleanup backend client
        await self.backend_client.cleanup()
        
        print("üéâ Demo completed!")
        print()
        print("üìä Check your data in H2 Console:")
        print("   URL: http://localhost:8080/h2-console")
        print("   JDBC URL: jdbc:h2:mem:testdb")
        print("   Username: sa")
        print("   Password: (leave empty)")
        print()
        print("üìã Useful queries:")
        print("   SELECT * FROM cctv WHERE stream_source = 'integration_test';")
        print("   SELECT * FROM detection WHERE correlation_id LIKE '%test%';")
        print()

def parse_arguments():
    """Parse command line arguments"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Real Integration Demo for AI-Backend System",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Use CPU with 3 streams
  python test/integration_tester.py --device cpu --streams 3

  # Use specific GPU with 2 streams  
  python test/integration_tester.py --device cuda:0 --streams 2

  # Auto-detect device with default settings
  python test/integration_tester.py
        """
    )
    
    parser.add_argument(
        "--device", 
        default="auto", 
        help="Device for AI models: auto, cpu, cuda, cuda:0, etc. (default: auto)"
    )
    
    parser.add_argument(
        "--streams", 
        type=int, 
        default=3,
        help="Number of video streams to process (1-6) (default: 3)"
    )
    
    parser.add_argument(
        "--window-size", 
        default="640x480",
        help="Window size: WIDTHxHEIGHT (default: 640x480)"
    )
    
    parser.add_argument(
        "--frame-delay",
        type=int,
        default=100,
        help="Milliseconds between frames (default: 100)"
    )
    
    
    return parser.parse_args()

def parse_window_size(window_size_str: str) -> Tuple[int, int]:
    """Parse window size string like '640x480' to tuple (640, 480)"""
    try:
        width, height = window_size_str.lower().split('x')
        return (int(width), int(height))
    except:
        print(f"‚ö†Ô∏è Invalid window size format: {window_size_str}, using default 640x480")
        return (640, 480)

async def main():
    """Main entry point"""
    args = parse_arguments()
    
    # Parse window size
    window_size = parse_window_size(args.window_size)
    
    # Print startup info
    print("üöÄ Real AI-Backend Integration Demo")
    print("=" * 60)
    print("This demo will show:")
    print("1. Real CCTV stream sync with VWorld geocoding")
    print("2. Multi-stream YOLO vehicle tracking")
    print("3. Illegal parking detection")
    print("4. Korean license plate recognition")
    print("5. Real backend API integration")
    print("6. H2 database storage verification")
    print("=" * 60)
    print()
    print("Configuration:")
    print(f"  Device: {args.device}")
    print(f"  Streams: {args.streams}")
    print(f"  Window Size: {window_size[0]}x{window_size[1]}")
    print(f"  Frame Delay: {args.frame_delay}ms")
    print("=" * 60)
    
    try:
        demo = RealIntegrationDemo(
            device=args.device, 
            num_streams=args.streams,
            window_size=window_size
        )
        
        # Set frame delay
        demo.frame_delay = args.frame_delay
        
        await demo.run_demo()
    
    except Exception as e:
        print(f"Demo failed: {e}")
        import traceback
        traceback.print_exc()
    
    print("\nDemo finished. Thank you!")

if __name__ == "__main__":
    # Handle EOF gracefully for non-interactive environments
    print("Press Enter to continue...")
    try:
        input()
    except EOFError:
        print("Running in non-interactive mode, continuing...")
    
    asyncio.run(main())